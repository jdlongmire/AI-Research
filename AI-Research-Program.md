# Research Program: AI Limitations and Opportunities

## A Framework for Understanding Artificial Intelligence Through the Origination-Derivation Distinction

---

## 1. Program Overview

### Working Title
*Infinite Information Space and the Categorical Limits of Artificial Intelligence*

### Central Research Question
What are the fundamental capabilities and limitations of AI systems, and can these be understood through a principled theoretical framework grounded in the distinction between origination and derivation?

### Scope and Aims
This research program investigates AI through a novel theoretical lens: the claim that human cognition has access to two coexistent primitive systems - Infinite Information Space and the three fundamental laws of logic - while AI systems are categorically derivative, operating downstream of human-generated data and unable to access these primitives directly.

The program aims to:
- Develop and refine this theoretical framework
- Apply the framework to documented AI phenomena (hallucination, reasoning failures, brittleness, creativity limits)
- Identify both the limitations and appropriate opportunities for AI systems
- Address ethical implications of the origination-derivation distinction
- Produce scholarly commentary on current AI research
- Generate testable predictions distinguishing the framework from alternatives

---

## 2. Theoretical Foundation

### 2.1 Two Coexistent Primitives

**Infinite Information Space**
- A non-physical space containing all possible configurations of information
- Includes contradictory configurations
- Not derived from or reducible to physical reality
- Serves as the "what" - the totality of conceivable content

**Three Fundamental Laws of Logic**
- Law of Identity (A = A)
- Law of Non-Contradiction (not both A and not-A)
- Law of Excluded Middle (either A or not-A)
- Ontologically primitive - not derived from more basic principles
- Serve as the "how" - the navigation system through Infinite Information Space

**Coexistence**
- Neither primitive is derived from the other
- The laws do not generate the coherent subset of the space; they navigate it
- The space is not defined as "what the laws permit" - it exists independently
- Open question: What contains these two coexistent primitives?

### 2.2 The Hierarchy of Actualization

1. **Infinite Information Space** - all possible configurations, including contradictions
2. **Conceptually accessible** - humans can explore contradictions, hold them in mind
3. **Logically navigable** - the coherent subset, filtered by the three laws
4. **Physically actualizable** - what can be instantiated in reality
5. **AI outputs** - derivative of human-generated data, already a filtered subset

### 2.3 The Logical Foundation of Physics

Physical laws presuppose and are constructed within logical constraints:
- Every physical law maintains identity
- No physical law permits contradictory states
- Physical laws describe determinate states (excluded middle)
- The mathematical structures used to formalize physics require logical coherence as a precondition
- Logical laws are prior to physical laws; the dependency runs one direction only

### 2.4 Origination vs Derivation

**Origination**
- Retrieving configurations from Infinite Information Space that are not derived from prior inputs
- Requires access to the space itself and the logical primitives for navigation
- The causal chain includes something entering from outside prior experience

**Derivation**
- Transformation of prior inputs according to learned patterns
- The causal chain runs: inputs â†’ processing â†’ outputs with no external entry point
- However sophisticated, remains confined to transformations within the training distribution

### 2.5 Human Access

Human minds have access to both primitive systems:
- Access to Infinite Information Space: capacity to conceive contradictions, impossible objects, counterfactuals, genuinely novel configurations
- Access to logical laws: capacity to recognize incoherence, filter for what could be actual, reason validly
- This dual access enables the full range of human cognition, including origination

### 2.6 The Actualization Constraint

- Humans can conceptualize contradictions but cannot physically actualize them
- Physical reality is constrained to the non-contradictory
- No actualization of physical reality violates the three fundamental laws
- This suggests the laws are not merely epistemic but track constraints on what can be real

---

## 3. Research Questions

### Primary Question
What are the fundamental capabilities and limitations of AI systems, and how does the origination-derivation distinction illuminate both?

### Subsidiary Questions

**Theoretical**
- Is the origination-derivation distinction categorical or a matter of degree?
- What is the nature of the faculty by which humans access the two primitives?
- What, if anything, contains the two coexistent primitives?
- Can the framework generate testable predictions?

**Empirical (AI Limitations)**
- Why is hallucination mathematically inevitable in LLMs?
- Why do reasoning failures persist despite scaling?
- Why does brittleness occur at distribution boundaries?
- Why do creativity measures show ceilings?

**Empirical (AI Opportunities)**
- In what domains do derivative systems excel?
- What forms of human-AI collaboration leverage both origination and derivation?
- How can AI augment rather than replace human origination?

**Ethical**
- What are the ethical implications of deploying derivative systems in domains requiring origination?
- How does the framework inform the alignment problem?
- What epistemic obligations follow from the origination-derivation distinction?

---

## 4. Research Agenda

### 4.1 AI Limitations

#### Category 1: Hallucination as Mathematically Inevitable
- Xu et al. (2024): Impossible to eliminate hallucination; LLMs cannot learn all computable functions
- Banerjee et al. (2024): Hallucinations stem from fundamental mathematical and logical structure; GÃ¶del's Incompleteness applies
- **Framework mapping**: Derivative systems cannot verify against ground truth they don't access

#### Category 2: Reasoning Failures as Structural
- LLMs cannot perform provably correct general-purpose formal reasoning
- LogicAsker: 29-90% reasoning failure rates across models
- Apple GSM-Symbolic: Performance degrades with minor wording changes
- **Framework mapping**: Mimicking logical patterns â‰  grasping logical laws as primitives

#### Category 3: Brittleness and Out-of-Distribution Failure
- Performance degrades sharply when inputs deviate from training distribution
- Models learn surface correlations, not underlying principles
- DNNs orders of magnitude more failure-prone than certified systems
- **Framework mapping**: Confined to training distribution, not navigating Infinite Information Space

#### Category 4: Stochastic Parrot Problem
- Bender et al.: LLMs probabilistically link words without considering meaning
- Words correspond to other words, not to experienced reality
- Cannot distinguish fact from fiction without external grounding
- **Framework mapping**: Words â†’ words, not words â†’ reality; no access to primitives

#### Category 5: Scaling Limits
- Diminishing returns documented across major labs
- 76% of AI researchers (2025 AAAI): Scaling unlikely to achieve AGI
- Sutskever: "Now we're back in the age of wonder and discovery"
- **Framework mapping**: More derivation does not become origination

#### Category 6: Creativity and Origination Ceiling
- Lovelace objection: "No pretensions whatever to originate anything"
- Mathematical ceiling: Creativity capped at 0.25 due to novelty-effectiveness tradeoff
- Output inherently derivative from training data
- **Framework mapping**: Cannot retrieve from space, only recombine within distribution

### 4.2 AI Opportunities

#### Domains Where Derivative Systems Excel
- Pattern recognition at scale
- Consistency checking within defined parameters
- Synthesis and summarization of existing information
- Execution of well-specified tasks
- Augmentation of human origination (drafting, iteration, refinement)

#### Human-AI Collaboration Models
- Human origination + AI derivation as complementary
- AI as tool for exploring implications of human-originated ideas
- AI for identifying patterns humans might miss within existing data
- Human verification and selection from AI-generated options

#### Appropriate Applications
- Domains where the task is transformation, not origination
- Tasks requiring speed and scale within known parameters
- Augmentation rather than replacement of human judgment
- Applications with robust verification mechanisms

### 4.3 AI Ethics

#### Deployment Implications
- Categorical limitation implies domains where AI deployment is inappropriate
- Substitution of derivative systems for origination-requiring tasks is category error
- Risk assessment must account for fundamental, not just empirical, limitations

#### The Alignment Problem
- If AI cannot access primitives, can it be truly "aligned" with human values?
- Or only approximate alignment within training distribution?
- Implications for safety at scale

#### Responsibility Attribution
- Derivative systems cannot bear moral responsibility
- Responsibility remains with humans who deploy and design systems
- Implications for liability and accountability frameworks

#### Epistemic Obligations
- Obligations to accurately represent AI capabilities
- Honest communication about origination-derivation distinction
- Risks of anthropomorphizing derivative systems

#### Replacement Ethics
- Ethical concerns with substituting AI for human judgment in:
  - Medical diagnosis requiring clinical understanding
  - Legal judgment requiring contextual wisdom
  - Creative work requiring authentic expression
  - Education requiring human formation

---

## 5. Objectives

1. **Develop and refine theoretical framework**
   - Clarify definitions and relationships
   - Address open questions
   - Respond to objections and alternatives

2. **Produce commentary articles on current AI research**
   - Apply framework to emerging findings
   - Offer principled explanations for documented phenomena
   - Engage ongoing discourse in AI/ML community

3. **Publish original research articles**
   - Theoretical contributions to philosophy of mind, philosophy of AI
   - Contributions to AI ethics literature
   - Interdisciplinary work connecting philosophy of logic, physics, and AI

4. **Identify empirical tests**
   - Generate predictions that distinguish framework from alternatives
   - Propose experimental designs where feasible
   - Identify phenomena that would falsify or support key claims

---

## 6. Methodology

### Theoretical Analysis
- Conceptual clarification of primitives and their relationships
- Logical analysis of the hierarchy of actualization
- Examination of entailments and implications

### Literature Synthesis
- Systematic review of documented AI limitations
- Integration of findings across hallucination, reasoning, brittleness, creativity research
- Engagement with philosophy of mind, logic, and AI ethics literatures

### Framework Application
- Mapping documented phenomena to theoretical framework
- Testing explanatory power against alternative accounts
- Identifying gaps and refinements needed

### Commentary and Critique
- Analysis of current AI research through framework lens
- Responsive publication addressing emerging findings
- Engagement with AI research community

---

## 7. Open Questions

### Theoretical
- What contains the two coexistent primitives? (Brute fact? Mind? Something else?)
- What is the nature of the faculty by which humans access the primitives?
- Is the origination-derivation distinction binary or continuous?
- How does a physical brain connect to non-physical primitives?

### Empirical
- What experimental designs could test the framework's predictions?
- Are there documented phenomena that would falsify key claims?
- How does the framework account for apparent AI "insights" or novel outputs?

### Ethical
- How do we determine appropriate vs inappropriate AI deployment domains?
- What governance structures follow from the framework?
- How do we balance AI benefits against risks of category confusion?

---

## 8. Planned Outputs

### Commentary Articles (Responsive to Current Research)
- Analysis of new hallucination research through framework lens
- Commentary on scaling debates and diminishing returns
- Response to claims of emergent capabilities
- Critique of AGI timeline predictions

### Original Research Articles

| Topic | Audience | Status |
|-------|----------|--------|
| AI Limitation Argument (categorical, not computational) | AI/AGI researchers, philosophy of mind | Planned |
| Logical Laws as Ontologically Primitive | Metaphysics, epistemology | Planned |
| Hierarchy of Actualization | Metaphysics, philosophy of logic | Planned |
| Two Coexistent Primitives | Foundations, metaphysics | Planned |
| Logical Foundation of Physics | Philosophy of physics | Planned |
| AI Ethics and the Origination-Derivation Distinction | AI ethics, technology ethics | Planned |

### Target Venues
- Philosophy journals (Mind, Philosophical Review, Philosophy & Phenomenological Research)
- AI/ML venues (commentary and critique)
- Interdisciplinary venues (AI & Society, Philosophy & Technology)
- Public-facing outlets for broader engagement

---

## 9. Principal Investigator

**James (JD) Longmire**
ORCID: 0009-0009-1383-7698
Northrop Grumman Fellow (unaffiliated research)

---

*Document version: 1.0*
*Last updated: December 2025*